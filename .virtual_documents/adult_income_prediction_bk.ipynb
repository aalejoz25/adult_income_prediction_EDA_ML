import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer
from sklearn.preprocessing import LabelEncoder
import wittgenstein as lw


url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'
columns = [
    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',
    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',
    'hours-per-week', 'native-country', 'income'
]
df = pd.read_csv(url, header=None, names=columns, na_values='?', skipinitialspace=True)
df.head()





# Limpieza de datos
print('Valores nulos por columna:')
print(df.isnull().sum())
# Eliminar filas con valores nulos
df_clean = df.dropna()
print(f'Shape después de eliminar nulos: {df_clean.shape}')
# Eliminar duplicados si existen
df_clean = df_clean.drop_duplicates()
print(f'Shape después de eliminar duplicados: {df_clean.shape}')
# Revisar tipos de datos
print(df_clean.dtypes)


# Porcentaje de valores nulos por columna
print('Porcentaje de valores nulos por columna:')
print((df.isnull().sum() / len(df) * 100).round(2))





# 2. Visualización de la forma del dataset
print('Forma del dataset (filas, columnas):', df_clean.shape)





# 3. Análisis de los tipos de datos de cada columna
print('Tipos de datos por columna:')
print(df_clean.dtypes)





# 4. Estadísticas descriptivas para variables numéricas
print('Estadísticas descriptivas:')
print(df_clean.describe().T[['mean','std','min','max']])








# Matriz de gráficos de dispersión entre variables numéricas
sns.pairplot(df_clean, vars=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], hue='income', diag_kind='hist', plot_kws={'alpha':0.5})
plt.show()








# 5. Visualización de la distribución de variables numéricas y outliers
num_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']
plt.figure(figsize=(15,10))
for i, col in enumerate(num_cols):
    plt.subplot(2,3,i+1)
    sns.histplot(df_clean[col].dropna(), bins=30, kde=True)
    plt.title(f'Histograma de {col}')
plt.tight_layout()
plt.show()
plt.figure(figsize=(15,10))
for i, col in enumerate(num_cols):
    plt.subplot(2,3,i+1)
    sns.boxplot(x=df_clean[col].dropna())
    plt.title(f'Boxplot de {col}')
plt.tight_layout()
plt.show()





# 6. Análisis de la variable objetivo ('income') y su distribución
print('Conteo de valores de income:')
print(df_clean['income'].value_counts())
plt.figure(figsize=(6,4))
sns.countplot(x='income', data=df_clean)
plt.title('Distribución de la variable objetivo (income)')
plt.show()








# Visualización: distribución de 'education' según 'income'
plt.figure(figsize=(10,5))
sns.countplot(x='education', hue='income', data=df_clean, order=df_clean['education'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de nivel educativo según income')
plt.show()





# Visualización: distribución de 'sex' según 'income'
plt.figure(figsize=(6,4))
sns.countplot(x='sex', hue='income', data=df_clean)
plt.title('Distribución de sexo según income')
plt.show()





# Visualización: horas trabajadas por semana vs. ingreso
plt.figure(figsize=(8,5))
sns.violinplot(x='income', y='hours-per-week', data=df_clean)
plt.title('Distribución de horas trabajadas por semana según income')
plt.show()





# Visualización: relación entre edad y horas trabajadas
plt.figure(figsize=(8,5))
sns.scatterplot(x='age', y='hours-per-week', hue='income', data=df_clean, alpha=0.5)
plt.title('Relación entre edad y horas trabajadas por semana')
plt.show()





# Matriz de correlación entre variables numéricas
plt.figure(figsize=(10,8))
corr = df_clean[['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Matriz de correlación entre variables numéricas')
plt.show()





# Visualización: distribución de 'workclass' según 'income'
plt.figure(figsize=(10,5))
sns.countplot(x='workclass', hue='income', data=df_clean, order=df_clean['workclass'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de workclass según income')
plt.show()





# Visualización: distribución de 'marital-status' según 'income'
plt.figure(figsize=(12,5))
sns.countplot(x='marital-status', hue='income', data=df_clean, order=df_clean['marital-status'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de marital-status según income')
plt.show()





# Visualización: distribución de 'occupation' según 'income'
plt.figure(figsize=(14,6))
sns.countplot(x='occupation', hue='income', data=df_clean, order=df_clean['occupation'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de occupation según income')
plt.show()





# Visualización: distribución de 'race' según 'income'
plt.figure(figsize=(8,4))
sns.countplot(x='race', hue='income', data=df_clean, order=df_clean['race'].value_counts().index)
plt.title('Distribución de race según income')
plt.show()





# Visualización: distribución de 'native-country' según 'income' (solo los 10 países más frecuentes)
top_countries = df_clean['native-country'].value_counts().index[:10]
plt.figure(figsize=(12,5))
sns.countplot(x='native-country', hue='income', data=df_clean[df_clean['native-country'].isin(top_countries)], order=top_countries)
plt.xticks(rotation=45)
plt.title('Distribución de native-country (top 10) según income')
plt.show()








# División de datos en entrenamiento y prueba
X = df_clean.drop('income', axis=1)
y = df_clean['income']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print('Forma de X_train:', X_train.shape)
print('Forma de X_test:', X_test.shape)
print('Distribución de la variable objetivo en el conjunto de entrenamiento:')
print(y_train.value_counts(normalize=True).round(3))
print('Distribución de la variable objetivo en el conjunto de prueba:')
print(y_test.value_counts(normalize=True).round(3))








#q4.2
# Calcular MI con dummies pero mapear al nombre original

# 2) Seleccionar Top-3 NUMÉRICAS por mutual information (para trazar regiones 2D continuas)
numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
mi = mutual_info_classif(X_train[numeric_cols], y_train, random_state=42)
feat_imp = pd.Series(mi, index=numeric_cols).sort_values(ascending=False)
top3 = feat_imp.head(3).index.tolist()

print("Top-3 numéricas (por mutual information):", top3)
pares = [(top3[0], top3[1]), (top3[0], top3[2]), (top3[1], top3[2])]






from sklearn.tree import DecisionTreeClassifier, export_text
modelos, pesos = {}, {}
for (c1, c2) in pares:
    Xtr = X_train[[c1, c2]]
    Xte = X_test[[c1, c2]]

    clf = DecisionTreeClassifier(
        criterion="gini",
        max_depth=3,            # interpretable
        min_samples_leaf=50,    # evita hojas diminutas
        random_state=42
    )
    clf.fit(Xtr, y_train)      # y_train = strings
    y_pred = clf.predict(Xte)  # y_pred = strings

    f1 = f1_score(y_test, y_pred, pos_label='>50K')  # <<< pos_label string
    modelos[(c1, c2)] = clf
    pesos[(c1, c2)] = f1

    print(f"\n=== Par: ({c1}, {c2}) | F1={f1:.3f} ===")
    print("Reglas IF–THEN (export_text):")
    print(export_text(clf, feature_names=[c1, c2]))





def ensamble_pred(X):
    # votos > 0 => '>50K', si no '<=50K'
    votos = np.zeros(len(X), dtype=float)
    for (c1, c2), clf in modelos.items():
        pred = clf.predict(X[[c1, c2]])  # strings
        # +peso si '>50K', -peso si '<=50K'
        votos += np.where(pred == '>50K', 1.0, -1.0) * pesos[(c1, c2)]
    return np.where(votos > 0, '>50K', '<=50K')

y_ens = ensamble_pred(X_test)
print("\n== Ensamble (3 pares) ==")
print("F1:", f1_score(y_test, y_ens, pos_label='>50K'))
print("Reporte:\n", classification_report(y_test, y_ens))
print("Matriz de confusión:\n", confusion_matrix(y_test, y_ens, labels=['<=50K','>50K']))









def decision_region_plot(clf, X_train, y_train, X_test, y_test, c1, c2, title_suffix=""):
    # Rango en percentiles (evita outliers extremos)
    x_min, x_max = np.percentile(X_train[c1], [5, 95])
    y_min, y_max = np.percentile(X_train[c2], [5, 95])

    xx, yy = np.meshgrid(
        np.linspace(x_min, x_max, 200),
        np.linspace(y_min, y_max, 200)
    )
    grid = pd.DataFrame({c1: xx.ravel(), c2: yy.ravel()})
    zz = clf.predict(grid)  # strings
    zz01 = (zz == '>50K').astype(int).reshape(xx.shape)

    plt.figure(figsize=(7,5))
    plt.pcolormesh(xx, yy, zz01, shading='auto')  # regiones 0/1 (colores por defecto)

    # Submuestreo para legibilidad
    rng = np.random.RandomState(42)
    idx = rng.choice(len(X_test), size=min(1500, len(X_test)), replace=False)
    Xs = X_test.iloc[idx][[c1, c2]]
    ys = (y_test.iloc[idx] == '>50K').astype(int)

    plt.scatter(Xs[c1], Xs[c2], c=ys, s=8, alpha=0.7)
    plt.xlabel(c1)
    plt.ylabel(c2)
    plt.title(f"Regiones de decisión (Árbol por par): {c1} vs {c2} {title_suffix}")
    plt.tight_layout()
    plt.show()

for (c1, c2), clf in modelos.items():
    decision_region_plot(clf, X_train, y_train, X_test, y_test, c1, c2)

















