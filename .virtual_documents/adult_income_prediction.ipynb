


# Importar librerías
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.metrics import accuracy_score, recall_score, classification_report, f1_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer
from sklearn.preprocessing import LabelEncoder


url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'
columns = [
    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',
    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',
    'hours-per-week', 'native-country', 'income'
]
df = pd.read_csv(url, header=None, names=columns, na_values='?', skipinitialspace=True)
df.head()





# Limpieza de datos
print('Valores nulos por columna:')
print(df.isnull().sum())
# Eliminar filas con valores nulos
df_clean = df.dropna()
print(f'Shape después de eliminar nulos: {df_clean.shape}')
# Eliminar duplicados si existen
df_clean = df_clean.drop_duplicates()
print(f'Shape después de eliminar duplicados: {df_clean.shape}')
# Revisar tipos de datos
print(df_clean.dtypes)


# Porcentaje de valores nulos por columna
print('Porcentaje de valores nulos por columna:')
print((df.isnull().sum() / len(df) * 100).round(2))





# 2. Visualización de la forma del dataset
print('Forma del dataset (filas, columnas):', df_clean.shape)





# 3. Análisis de los tipos de datos de cada columna
print('Tipos de datos por columna:')
print(df_clean.dtypes)





# 4. Estadísticas descriptivas para variables numéricas
print('Estadísticas descriptivas:')
print(df_clean.describe().T[['mean','std','min','max']])








# Matriz de gráficos de dispersión entre variables numéricas
sns.pairplot(df_clean, vars=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], hue='income', diag_kind='hist', plot_kws={'alpha':0.5})
plt.show()








# 5. Visualización de la distribución de variables numéricas y outliers
num_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']
plt.figure(figsize=(15,10))
for i, col in enumerate(num_cols):
    plt.subplot(2,3,i+1)
    sns.histplot(df_clean[col].dropna(), bins=30, kde=True)
    plt.title(f'Histograma de {col}')
plt.tight_layout()
plt.show()
plt.figure(figsize=(15,10))
for i, col in enumerate(num_cols):
    plt.subplot(2,3,i+1)
    sns.boxplot(x=df_clean[col].dropna())
    plt.title(f'Boxplot de {col}')
plt.tight_layout()
plt.show()





# 6. Análisis de la variable objetivo ('income') y su distribución
print('Conteo de valores de income:')
print(df_clean['income'].value_counts())
plt.figure(figsize=(6,4))
sns.countplot(x='income', data=df_clean)
plt.title('Distribución de la variable objetivo (income)')
plt.show()








# Visualización: distribución de 'education' según 'income'
plt.figure(figsize=(10,5))
sns.countplot(x='education', hue='income', data=df_clean, order=df_clean['education'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de nivel educativo según income')
plt.show()





# Visualización: distribución de 'sex' según 'income'
plt.figure(figsize=(6,4))
sns.countplot(x='sex', hue='income', data=df_clean)
plt.title('Distribución de sexo según income')
plt.show()





# Visualización: horas trabajadas por semana vs. ingreso
plt.figure(figsize=(8,5))
sns.violinplot(x='income', y='hours-per-week', data=df_clean)
plt.title('Distribución de horas trabajadas por semana según income')
plt.show()





# Visualización: relación entre edad y horas trabajadas
plt.figure(figsize=(8,5))
sns.scatterplot(x='age', y='hours-per-week', hue='income', data=df_clean, alpha=0.5)
plt.title('Relación entre edad y horas trabajadas por semana')
plt.show()





# Matriz de correlación entre variables numéricas
plt.figure(figsize=(10,8))
corr = df_clean[['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Matriz de correlación entre variables numéricas')
plt.show()





# Visualización: distribución de 'workclass' según 'income'
plt.figure(figsize=(10,5))
sns.countplot(x='workclass', hue='income', data=df_clean, order=df_clean['workclass'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de workclass según income')
plt.show()





# Visualización: distribución de 'marital-status' según 'income'
plt.figure(figsize=(12,5))
sns.countplot(x='marital-status', hue='income', data=df_clean, order=df_clean['marital-status'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de marital-status según income')
plt.show()





# Visualización: distribución de 'occupation' según 'income'
plt.figure(figsize=(14,6))
sns.countplot(x='occupation', hue='income', data=df_clean, order=df_clean['occupation'].value_counts().index)
plt.xticks(rotation=45)
plt.title('Distribución de occupation según income')
plt.show()





# Visualización: distribución de 'race' según 'income'
plt.figure(figsize=(8,4))
sns.countplot(x='race', hue='income', data=df_clean, order=df_clean['race'].value_counts().index)
plt.title('Distribución de race según income')
plt.show()





# Visualización: distribución de 'native-country' según 'income' (solo los 10 países más frecuentes)
top_countries = df_clean['native-country'].value_counts().index[:10]
plt.figure(figsize=(12,5))
sns.countplot(x='native-country', hue='income', data=df_clean[df_clean['native-country'].isin(top_countries)], order=top_countries)
plt.xticks(rotation=45)
plt.title('Distribución de native-country (top 10) según income')
plt.show()








# División de datos en entrenamiento y prueba
X = df_clean.drop('income', axis=1)
y = df_clean['income']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print('Forma de X_train:', X_train.shape)
print('Forma de X_test:', X_test.shape)
print('Distribución de la variable objetivo en el conjunto de entrenamiento:')
print(y_train.value_counts(normalize=True).round(3))
print('Distribución de la variable objetivo en el conjunto de prueba:')
print(y_test.value_counts(normalize=True).round(3))





#q4.2
# Calcular MI con dummies pero mapear al nombre original

# 2) Seleccionar Top-3 NUMÉRICAS por mutual information (para trazar regiones 2D continuas)
numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
mi = mutual_info_classif(X_train[numeric_cols], y_train, random_state=42)
feat_imp = pd.Series(mi, index=numeric_cols).sort_values(ascending=False)
top3 = feat_imp.head(3).index.tolist()

print("Top-3 numéricas (por mutual information):", top3)
pares = [(top3[0], top3[1]), (top3[0], top3[2]), (top3[1], top3[2])]






from sklearn.tree import DecisionTreeClassifier, export_text
modelos, pesos = {}, {}
for (c1, c2) in pares:
    Xtr = X_train[[c1, c2]]
    Xte = X_test[[c1, c2]]

    clf = DecisionTreeClassifier(
        criterion="gini",
        max_depth=3,            # interpretable
        min_samples_leaf=50,    # evita hojas diminutas
        random_state=42
    )
    clf.fit(Xtr, y_train)      # y_train = strings
    y_pred = clf.predict(Xte)  # y_pred = strings
    y_pred_modelo_1 = y_pred
    y_pred_modelo_1_proba = clf.predict_proba(Xte)  # y_pred = strings

    f1 = f1_score(y_test, y_pred, pos_label='>50K')  # <<< pos_label string
    modelos[(c1, c2)] = clf
    pesos[(c1, c2)] = f1

    print(f"\n=== Par: ({c1}, {c2}) | F1={f1:.3f} ===")
    print("Reglas IF–THEN (export_text):")
    print(export_text(clf, feature_names=[c1, c2]))





def ensamble_pred(X):
    # votos > 0 => '>50K', si no '<=50K'
    votos = np.zeros(len(X), dtype=float)
    for (c1, c2), clf in modelos.items():
        pred = clf.predict(X[[c1, c2]])  # strings
        # +peso si '>50K', -peso si '<=50K'
        votos += np.where(pred == '>50K', 1.0, -1.0) * pesos[(c1, c2)]
    return np.where(votos > 0, '>50K', '<=50K')

y_ens = ensamble_pred(X_test)
print("\n== Ensamble (3 pares) ==")
print("F1:", f1_score(y_test, y_ens, pos_label='>50K'))
print("Reporte:\n", classification_report(y_test, y_ens))
print("Matriz de confusión:\n", confusion_matrix(y_test, y_ens, labels=['<=50K','>50K']))









def decision_region_plot(clf, X_train, y_train, X_test, y_test, c1, c2, title_suffix=""):
    # Rango en percentiles (evita outliers extremos)
    x_min, x_max = np.percentile(X_train[c1], [5, 95])
    y_min, y_max = np.percentile(X_train[c2], [5, 95])

    xx, yy = np.meshgrid(
        np.linspace(x_min, x_max, 200),
        np.linspace(y_min, y_max, 200)
    )
    grid = pd.DataFrame({c1: xx.ravel(), c2: yy.ravel()})
    zz = clf.predict(grid)  # strings
    zz01 = (zz == '>50K').astype(int).reshape(xx.shape)

    plt.figure(figsize=(7,5))
    plt.pcolormesh(xx, yy, zz01, shading='auto')  # regiones 0/1 (colores por defecto)

    # Submuestreo para legibilidad
    rng = np.random.RandomState(42)
    idx = rng.choice(len(X_test), size=min(1500, len(X_test)), replace=False)
    Xs = X_test.iloc[idx][[c1, c2]]
    ys = (y_test.iloc[idx] == '>50K').astype(int)

    plt.scatter(Xs[c1], Xs[c2], c=ys, s=8, alpha=0.7)
    plt.xlabel(c1)
    plt.ylabel(c2)
    plt.title(f"Regiones de decisión (Árbol por par): {c1} vs {c2} {title_suffix}")
    plt.tight_layout()
    plt.show()

for (c1, c2), clf in modelos.items():
    decision_region_plot(clf, X_train, y_train, X_test, y_test, c1, c2)





















# Label Encoding para todas las variables categóricas
df_encoded = df_clean.copy()
cat_cols = df_encoded.select_dtypes(include=['object']).columns
le_dict = {}
for col in cat_cols:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    le_dict[col] = le
df_encoded





# Se eliminan columnas que no se incluiran en el modelo segun el analisis
df_tree_model = df_encoded.drop(columns=['workclass', 'fnlwgt', 'education', 'marital-status', 'relationship', 'race', 'sex', 'native-country'])


df_tree_model


X = df_tree_model.drop('income', axis=1)
y = df_tree_model['income']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print('Forma de X_train:', X_train.shape)
print('Forma de X_test:', X_test.shape)
print('Distribución de la variable objetivo en el conjunto de entrenamiento:')
print(y_train.value_counts(normalize=True).round(3))
print('Distribución de la variable objetivo en el conjunto de prueba:')
print(y_test.value_counts(normalize=True).round(3))





# Definir combinaciones de hiperparámetros a probar
param_grid = {
    'max_depth': [1,2,3,4,5,6,7,8,9,10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

import itertools
results = []

for max_depth, min_samples_split, min_samples_leaf, criterion in itertools.product(
    param_grid['max_depth'], param_grid['min_samples_split'], param_grid['min_samples_leaf'], param_grid['criterion']):
    tree = DecisionTreeClassifier(
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        criterion=criterion,
        random_state=42
    )
    tree.fit(X_train, y_train)
    y_pred = tree.predict(X_test)
    y_pred_modelo_2 = y_pred
    y_pred_modelo_2_proba = tree.predict_proba(X_test)
    acc = accuracy_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    results.append({
        'max_depth': max_depth,
        'min_samples_split': min_samples_split,
        'min_samples_leaf': min_samples_leaf,
        'criterion': criterion,
        'accuracy': acc,
        'recall': rec
    })

# Convertir resultados a DataFrame
results_df = pd.DataFrame(results)

# Mostrar los mejores hiperparámetros según accuracy
best_acc = results_df.sort_values('accuracy', ascending=False).head(1)
print('Mejores hiperparámetros según accuracy:')
print(best_acc)

# Mostrar los mejores hiperparámetros según recall
best_rec = results_df.sort_values('recall', ascending=False).head(1)
print('\nMejores hiperparámetros según recall:')
print(best_rec)


from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Entrenar el árbol de decisión
tree = DecisionTreeClassifier(max_depth=10,min_samples_split=2,min_samples_leaf=2,criterion='gini',random_state=42)
tree.fit(X_train, y_train)

# Predicciones
y_pred = tree.predict(X_test)

# Evaluación
print('Accuracy en test:', accuracy_score(y_test, y_pred))
print('\nReporte de clasificación:')
print(classification_report(y_test, y_pred))
print('\nMatriz de confusión:')
print(confusion_matrix(y_test, y_pred))


# Visualización del árbol de decisión generado
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt
plt.figure(figsize=(20,8))
plot_tree(tree, feature_names=X_train.columns, class_names=['<=50K','>50K'], filled=True, fontsize=10)
plt.title('Árbol de decisión')
plt.show()


# Matriz de confusión con seaborn
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['<=50K', '>50K'], yticklabels=['<=50K', '>50K'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de confusión (Árbol de decisión)')
plt.show()








df_one_hot = df_clean.copy()
df_one_hot.drop(columns=['education'], inplace=True)
df_one_hot = pd.get_dummies(df_one_hot, columns=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], drop_first=True)



df_one_hot_encoded = df_one_hot.copy()
cat_cols = df_one_hot_encoded.select_dtypes(include=['object']).columns
le_dict = {}
for col in cat_cols:
    le = LabelEncoder()
    df_one_hot_encoded[col] = le.fit_transform(df_one_hot_encoded[col])
    le_dict[col] = le
df_one_hot_encoded.head(1)


X_one_hot = df_one_hot_encoded.drop('income', axis=1)
y_one_hot = df_one_hot_encoded['income']
X_train_one_hot, X_test_one_hot, y_train_one_hot, y_test_one_hot = train_test_split(
    X_one_hot, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot
)

print('Forma de X_train_one_hot:', X_train_one_hot.shape)
print('Forma de X_test_one_hot:', X_test_one_hot.shape)
print('Distribución de la variable objetivo en el conjunto de entrenamiento:')
print(y_train_one_hot.value_counts(normalize=True).round(3))
print('Distribución de la variable objetivo en el conjunto de prueba:')
print(y_test_one_hot.value_counts(normalize=True).round(3))


best_k = None
best_acc = 0
best_rec = 0
scores = []

for k in range(1, 21):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_one_hot, y_train_one_hot)
    y_pred_knn = knn.predict(X_test_one_hot)
    acc = accuracy_score(y_test_one_hot, y_pred_knn)
    rec = recall_score(y_test_one_hot, y_pred_knn)
    scores.append({'k': k, 'accuracy': acc, 'recall': rec})
    if acc > best_acc:
        best_acc = acc
        best_rec = rec
        best_k = k

print(f"Mejor k según accuracy: {best_k}")
print(f"Accuracy: {best_acc:.4f}, Recall: {best_rec:.4f}")

# Mostrar todos los scores en un DataFrame
scores_df = pd.DataFrame(scores)
print(scores_df.sort_values('accuracy', ascending=False).head())


scores_df.sort_values('accuracy', ascending=False)


# Entrenamiento y evaluación de KNN con k=19 usando datos one-hot
knn_19 = KNeighborsClassifier(n_neighbors=19)
knn_19.fit(X_train_one_hot, y_train_one_hot)
y_pred_knn_19 = knn_19.predict(X_test_one_hot)
y_pred_modelo_3 = y_pred_knn_19
y_pred_modelo_3_proba = knn_19.predict_proba(X_test_one_hot)

print('Accuracy en test (k=19):', accuracy_score(y_test_one_hot, y_pred_knn_19))
print('\nReporte de clasificación (k=19):')
print(classification_report(y_test_one_hot, y_pred_knn_19))
print('\nMatriz de confusión (k=19):')
print(confusion_matrix(y_test_one_hot, y_pred_knn_19))


cm_knn_19 = confusion_matrix(y_test_one_hot, y_pred_knn_19)
plt.figure(figsize=(6,4))
sns.heatmap(cm_knn_19, annot=True, fmt='d', cmap='Blues', xticklabels=['<=50K', '>50K'], yticklabels=['<=50K', '>50K'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de confusión (KNN k=19)')
plt.show()











# y_pred_proba_modelo1: probabilidades de predicción para la clase positiva (>50K)
y_pred_modelo_1_num = (y_pred_modelo_1 == '>50K').astype(int)
class_names = ['<=50K', '>50K']
# --- Reporte de Clasificación (Precision, Recall, F1-Score) ---
print("Resultados para el Modelo 1")
# Asumiendo que la clase '>50K' está codificada como 1 
print(classification_report(y_test, y_pred_modelo_1_num, target_names=class_names))
# --- Puntuación AUC-ROC ---
auc_score = roc_auc_score(y_test, y_pred_modelo_1_proba[:,1])
print(f"AUC Score del Modelo 1: {auc_score:.4f}")

cm = confusion_matrix(y_test, y_pred_modelo_1_num)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['<=50K', '>50K'], yticklabels=['<=50K', '>50K'])
plt.xlabel('Predicción')
plt.ylabel('Valor Real')
plt.title('Matriz de Confusión - Modelo 1')
plt.show()


# y_pred_proba_modelo1: probabilidades de predicción para la clase positiva (>50K)
y_pred_modelo_2_num = (y_pred_modelo_2 == '>50K').astype(int)
class_names = ['<=50K', '>50K']
# --- Reporte de Clasificación (Precision, Recall, F1-Score) ---
print("Resultados para el Modelo 2")
# Asumiendo que la clase '>50K' está codificada como 1 
print(classification_report(y_test, y_pred_modelo_2_num, target_names=class_names))
# --- Puntuación AUC-ROC ---
auc_score = roc_auc_score(y_test, y_pred_modelo_2_proba[:,1])
print(f"AUC Score del Modelo 2: {auc_score:.4f}")

# --- Matriz de Confusión Visual ---
cm = confusion_matrix(y_test, y_pred_modelo_2_num)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['<=50K', '>50K'], yticklabels=['<=50K', '>50K'])
plt.xlabel('Predicción')
plt.ylabel('Valor Real')
plt.title('Matriz de Confusión - Modelo 2')
plt.show()


# y_pred_proba_modelo1: probabilidades de predicción para la clase positiva (>50K)
y_pred_modelo_3_num = (y_pred_modelo_3 == '>50K').astype(int)
class_names = ['<=50K', '>50K']
# --- Reporte de Clasificación (Precision, Recall, F1-Score) ---
print("Resultados para el Modelo 3")
print(classification_report(y_test, y_pred_modelo_3_num, target_names=class_names))
# --- Puntuación AUC-ROC ---
auc_score = roc_auc_score(y_test, y_pred_modelo_3_proba[:,1])
print(f"AUC Score del Modelo 2: {auc_score:.4f}")

# --- Matriz de Confusión Visual ---
cm = confusion_matrix(y_test, y_pred_modelo_3_num)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['<=50K', '>50K'], yticklabels=['<=50K', '>50K'])
plt.xlabel('Predicción')
plt.ylabel('Valor Real')
plt.title('Matriz de Confusión - Modelo 3')
plt.show()






